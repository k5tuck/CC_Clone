# Ollama Configuration
OLLAMA_ENDPOINT=http://localhost:11434
OLLAMA_MODEL=llama3.1:latest

# Alternative Models (uncomment to use)
# OLLAMA_MODEL=mistral:latest
# OLLAMA_MODEL=codellama:latest
# OLLAMA_MODEL=deepseek-coder:latest

# Agent Configuration
AGENT_HOME=~/.local-agent
MAX_ITERATIONS=10

# Output Directories
PLANS_DIR=./plans
TEMPLATES_DIR=./.claude/prompts

# Execution Settings
AUTO_EXECUTE=false
DRY_RUN=false
