# Selek - Advanced Multi-Agent AI Framework

[![TypeScript](https://img.shields.io/badge/TypeScript-5.0+-blue.svg)](https://www.typescriptlang.org/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)
[![Ollama](https://img.shields.io/badge/Ollama-Compatible-orange.svg)](https://ollama.ai/)

**Selek** is a powerful, extensible TypeScript framework for building sophisticated multi-agent AI systems with local LLM support. Featuring an interactive Terminal User Interface (TUI), dynamic model selection, intelligent agent orchestration, ephemeral knowledge graphs, and comprehensive tool integration with built-in safety mechanisms.

---

## âœ¨ Key Features

### ğŸ¯ Multi-Agent Orchestration
- **Dynamic Agent System**: Create, manage, and execute specialized agents for specific tasks
- **Agent Templates**: Export and install reusable agent configurations
- **Intelligent Auto-Suggest**: AI-powered agent recommendations based on user intent (toggle on/off)
- **Real-time Status Tracking**: Monitor agent execution, progress, and activity logs
- **Plan Approval Workflow**: Review and approve agent execution plans before running

### ğŸ–¥ï¸ Interactive Terminal UI (TUI)
- **Real-time Streaming**: Live response streaming with visual feedback
- **Command Autocomplete**: Tab completion for all available commands
- **Visual Agent Management**: Browse, create, and manage agents directly in the TUI
- **Status Bar**: Live display of system status, model info, and auto-suggest state
- **Message History**: Full conversation history with role-based formatting

### ğŸ¤– LLM & Model Management
- **Multi-Provider Support**: Ollama (local), Anthropic Claude, and OpenAI GPT
- **Dynamic Provider Switching**: Switch between providers on-the-fly (`/provider`, `/providers`)
- **Dynamic Model Switching**: Change models on-the-fly without restarting (`/model`, `/models`)
- **Multi-Model Support**: Use different models for different tasks
- **Automatic Model Discovery**: Lists all available models per provider
- **Streaming Responses**: Real-time token-by-token response streaming

### ğŸ› ï¸ Comprehensive Tool System
- **File Operations**: Read, write, edit files with intelligent context awareness
- **File Safety Validation**: Enforces read-before-write rule to prevent accidental overwrites
- **Bash Execution**: Execute shell commands with 12-pattern security blacklist
- **Search Capabilities**: Glob patterns, regex search, and content grep
- **Tool-Aware LLM**: Automatic tool selection and execution during conversations
- **MCP Support**: Model Context Protocol integration for extended capabilities
- **Custom Tools**: Extensible tool registration system

### ğŸ§© Skills Framework
- **Reusable Skills**: Modular, composable skill definitions
- **Skill Discovery**: Automatic skill loading and registration
- **Skill-Aware Agents**: Agents can leverage available skills dynamically
- **Skill Manager**: Central management for all skills

### ğŸ§  Knowledge Graph & Memory
- **Ephemeral Knowledge Graph**: Track entities (files, agents, tasks) and relationships
- **Vector Database**: Lightweight in-memory vector store for semantic search
- **Agent History**: Learn from past agent executions and solutions
- **File Context Analysis**: Understand dependencies before modifying code
- **Graph Traversal**: Discover connections through relationship following
- **Knowledge Tools**: 5 specialized tools for querying and storing knowledge

### ğŸ›¡ï¸ System Checks & Balances
- **File Read-Before-Write**: Prevents accidental overwrites of existing files
- **Command Blacklist**: Blocks 12 dangerous command patterns (`rm -rf`, etc.)
- **Tool Validation**: 30+ validation mechanisms across the system
- **Provider Health Checks**: Automatic validation of LLM provider configurations
- **Session Tracking**: File access tracking scoped to conversation sessions
- **Clear Error Messages**: Detailed guidance when validation fails

### ğŸ’¾ Conversation Management
- **History Persistence**: Automatic conversation history saving
- **Context Loading**: Project context awareness for better responses
- **Message Formatting**: Markdown support with syntax highlighting
- **Conversation Restore**: Resume previous conversations

---

## ğŸš€ Quick Start

### Prerequisites
- **Node.js**: v18.0 or higher
- **Ollama**: For local LLM inference ([Install Ollama](https://ollama.ai/))
- **TypeScript**: Included in dependencies

### Installation

1. **Clone the repository:**
```bash
git clone https://github.com/k5tuck/CC_Clone.git selek
cd selek
```

2. **Install dependencies:**
```bash
npm install
# or
pnpm install
```

3. **Set up environment:**
```bash
cp env.example .env
```

4. **Configure Ollama endpoint and model** (`.env`):
```env
OLLAMA_ENDPOINT=http://localhost:11434
OLLAMA_MODEL=llama3.1:latest
```

5. **Build the project:**
```bash
npm run build
```

### Running Selek

#### Interactive TUI (Recommended)
```bash
npm run tui
```

#### CLI Mode
```bash
npm run cli
```

---

## ğŸ“– Usage Guide

### TUI Commands

#### Chat & System
- `/help` - Show all available commands
- `/clear` - Clear conversation history
- `/reload` - Reload agents and skills

#### Agent Management
- `/agents` - Toggle agent list display
- `/agent-list` - List all available agents
- `/agent-view <id>` - View detailed agent information
- `/agent-delete <id>` - Delete an agent
- `/agent <id> <task>` - Execute a specific agent with a task
- `/create-agent` - Launch agent creation wizard
- `/autosuggest` - Toggle agent auto-suggest on/off

#### Model & Provider Management
- `/providers` - List all available providers (Ollama, Anthropic, OpenAI)
- `/provider <name>` - Switch to a different provider
- `/models` - List all available models for current provider
- `/model <name>` - Switch to a different model
- `/model-current` - Display current provider, model, and endpoint

#### Templates
- `/templates` - List agent templates
- `/template-export <id> [category]` - Export agent as template
- `/template-install <template-id> <new-id>` - Install template as new agent

#### Plan Approval
- `/approve` - Approve a pending agent execution plan
- `/reject` - Reject a pending plan

#### Other
- `/skills` - Toggle skills list display
- `/mcp` - Show MCP server status and available tools

### Creating Custom Agents

Use the interactive agent creator:
```
/create-agent
```

Follow the prompts to define:
1. **Agent ID**: Unique identifier (e.g., `code-reviewer`)
2. **Name**: Display name (e.g., `Code Reviewer`)
3. **Description**: What the agent does
4. **Avatar**: Emoji representation
5. **Capabilities**: Comma-separated list
6. **Keywords**: Activation keywords for auto-suggest
7. **System Prompt**: Agent's behavior instructions

### Agent Structure

Agents are stored in `./agents/<agent-id>/AGENT.md`:

```markdown
---
id: code-reviewer
name: Code Reviewer
description: Reviews code for best practices and issues
avatar: ğŸ”
capabilities: [code-review, analysis, suggestions]
activation_keywords: [review, analyze, check]
requires_approval: false
max_iterations: 10
---

# System Prompt
You are an expert code reviewer. Analyze code for...
```

---

## ğŸ—ï¸ Architecture

### Core Components

```
selek/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ tui/                    # Terminal UI
â”‚   â”‚   â”œâ”€â”€ multiagent-tui.tsx  # Main TUI component
â”‚   â”‚   â””â”€â”€ integration/        # Orchestrator bridge
â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”œâ”€â”€ agents/             # Agent system
â”‚   â”‚   â”‚   â”œâ”€â”€ AgentSystem.ts  # Core orchestration
â”‚   â”‚   â”‚   â”œâ”€â”€ AgentManager.ts # CRUD operations
â”‚   â”‚   â”‚   â”œâ”€â”€ SystematicAgentPrompts.ts # Agent prompts with KG docs
â”‚   â”‚   â”‚   â””â”€â”€ SkillAwareAgent.ts
â”‚   â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â”‚   â””â”€â”€ ollama-client.ts # Ollama integration
â”‚   â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”‚   â””â”€â”€ LLMConfig.ts    # Multi-provider configuration
â”‚   â”‚   â”œâ”€â”€ knowledge/          # Knowledge graph system
â”‚   â”‚   â”‚   â””â”€â”€ KnowledgeGraph.ts # Entity & relationship tracking
â”‚   â”‚   â”œâ”€â”€ memory/             # Memory & vector store
â”‚   â”‚   â”‚   â”œâ”€â”€ VectorStore.ts  # In-memory vector database
â”‚   â”‚   â”‚   â””â”€â”€ EmbeddingProvider.ts
â”‚   â”‚   â”œâ”€â”€ streaming/          # Real-time streaming
â”‚   â”‚   â”‚   â””â”€â”€ StreamingClientWithTools.ts # File access tracking
â”‚   â”‚   â”œâ”€â”€ skills/             # Skills framework
â”‚   â”‚   â”œâ”€â”€ orchestrator/       # Multi-agent orchestrator
â”‚   â”‚   â”œâ”€â”€ history/            # Conversation management
â”‚   â”‚   â”œâ”€â”€ tools/              # Tool implementations
â”‚   â”‚   â”‚   â”œâ”€â”€ toolFunctions.ts # File validation & tracking
â”‚   â”‚   â”‚   â””â”€â”€ knowledge-tools.ts # KG query tools
â”‚   â”‚   â””â”€â”€ providers/          # LLM provider integrations
â”‚   â”‚       â”œâ”€â”€ AnthropicProvider.ts
â”‚   â”‚       â”œâ”€â”€ OpenAIProvider.ts
â”‚   â”‚       â””â”€â”€ OllamaProvider.ts
â”‚   â”œâ”€â”€ mcp/                    # Model Context Protocol
â”‚   â””â”€â”€ cli.ts                  # CLI entry point
â”œâ”€â”€ agents/                     # Agent definitions with KG examples
â”œâ”€â”€ skills/                     # Skill definitions
â”œâ”€â”€ docs/                       # Documentation
â”‚   â”œâ”€â”€ SYSTEM_CHECKS.md        # All validation mechanisms
â”‚   â””â”€â”€ FILE_READ_WRITE_VALIDATION.md # File safety docs
â”œâ”€â”€ config/                     # Configuration files
â”‚   â””â”€â”€ mcp-servers.json        # MCP server config
â””â”€â”€ .conversation_history/      # Saved conversations
```

### Technology Stack

- **Runtime**: Node.js with TypeScript
- **UI Framework**: Ink (React for terminals)
- **LLM Integration**: Ollama via REST API
- **State Management**: React hooks
- **File I/O**: Node.js fs/promises
- **Process Management**: child_process
- **Data Formats**: YAML frontmatter, JSON, Markdown

---

## ğŸ”§ Configuration

### Environment Variables

```env
# Ollama Configuration (Default Provider)
OLLAMA_ENDPOINT=http://localhost:11434
OLLAMA_MODEL=llama3.1:latest

# Anthropic Configuration (Optional)
ANTHROPIC_API_KEY=your-api-key-here

# OpenAI Configuration (Optional)
OPENAI_API_KEY=your-api-key-here

# Supported Ollama models (examples):
# - llama3.1:latest
# - mistral:latest
# - codellama:latest
# - deepseek-coder:latest
# - qwen2.5-coder:latest
```

**Multi-Provider Support:**
- Use `/providers` to see all configured providers
- Use `/provider <name>` to switch between Ollama, Anthropic, or OpenAI
- API keys for cloud providers are stored securely in `~/.local-agent/llm-config.json`

### MCP Server Configuration

Create `config/mcp-servers.json`:

```json
{
  "servers": [
    {
      "name": "filesystem",
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-filesystem", "/path/to/workspace"],
      "env": {}
    }
  ]
}
```

---

## ğŸ¨ Features in Detail

### Multi-Provider Support

Switch between LLM providers seamlessly:

```
> /providers
**Available Providers:**

â€¢ ollama (current) - âœ“ Enabled, ğŸ”‘ Configured - Model: llama3.1:latest
â€¢ anthropic - âœ— Enabled, âŒ Configured - Model: claude-3-5-sonnet-20241022
â€¢ openai - âœ— Enabled, âŒ Configured - Model: gpt-4-turbo

**Current:** ollama

Use /provider <name> to switch providers.

> /provider anthropic
âœ… Switched to provider: anthropic
ğŸ“¦ Default model: claude-3-5-sonnet-20241022
```

### Dynamic Model Selection

Switch between models for the current provider:

```
> /models
Available Models:

â€¢ llama3.1:latest âœ“ (current)
â€¢ mistral:latest
â€¢ codellama:latest
â€¢ deepseek-coder:latest

> /model codellama:latest
âœ… Switched to model: codellama:latest
```

### Intelligent Agent Auto-Suggest

The system analyzes your input and suggests the most appropriate agent:

```
> Review my authentication code

ğŸ’¡ Agent Suggestion: ğŸ” Code Reviewer might be best suited for this task.
   Reason: Matched keywords: review
   Confidence: 85%

   Use `/agent code-reviewer Review my authentication code` to execute.
```

Toggle auto-suggest on/off with `/autosuggest`.

### Real-Time Status Bar

The bottom status bar displays:
- **System Status**: Initializing, Ready, Streaming, or Error
- **Agent Count**: Number of available agents
- **Skills Count**: Number of loaded skills
- **Current Provider**: Active LLM provider (Ollama, Anthropic, OpenAI)
- **Current Model**: Active model for the provider
- **AutoSuggest Status**: ON (green) or OFF (gray)

Example:
```
â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®
â”‚ â— Ready â€¢ 8 agents â€¢ 5 skills â€¢ Provider: ollama â€¢ Model: llama3.1:latest â€¢ AutoSuggest: ON â”‚
â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯
```

### Tool-Aware Conversations

The LLM automatically uses available tools during conversations:

```
> What files are in the src directory?

[Agent uses glob tool to search]

I found the following files in src/:
- src/tui/multiagent-tui.tsx
- src/lib/agents/AgentSystem.ts
- src/lib/llm/ollama-client.ts
...
```

### Knowledge Graph & Memory Tools

Agents can use specialized knowledge tools to understand context and learn from history:

**Available Knowledge Tools:**
1. **queryKnowledgeGraph** - Query entities (Files, Agents, Tasks, etc.) and relationships
2. **getFileContext** - Get comprehensive file dependencies before modifying
3. **getAgentHistory** - Learn from past agent executions and solutions
4. **storeKnowledge** - Record discoveries, solutions, and task completions
5. **findRelatedEntities** - Traverse the knowledge graph to discover connections

**Example Usage:**
```typescript
// Before modifying a file, check its context
const context = await getFileContext({ filePath: "src/lib/auth.ts" });
// Returns: { dependencies, dependents, functions, modifiedBy, tests }

// Learn from past work
const history = await getAgentHistory({ agentName: "code-agent" });
// Returns: tasks completed, files modified, solutions applied
```

See [Agent Definitions](./agents/) for examples of how agents use these tools.

### File Safety Validation

The system enforces a **read-before-write rule** to prevent accidental overwrites:

```typescript
// âŒ This will throw FileNotReadError
await writeFile({ path: 'existing.txt', content: 'new content' });
// Error: File has not been read yet. Read it first before writing to it

// âœ… Correct approach
await readFile({ path: 'existing.txt' });
await writeFile({ path: 'existing.txt', content: 'updated content' });
// Success!
```

**Benefits:**
- Prevents accidental file overwrites
- Enforces agents to understand context before changes
- Session-scoped tracking (resets between conversations)
- New files can be created without reading

See [FILE_READ_WRITE_VALIDATION.md](./docs/FILE_READ_WRITE_VALIDATION.md) for complete documentation.

---

## ğŸ¤ Contributing

Contributions are welcome! Please follow these guidelines:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## ğŸ“ Roadmap

### âœ… Completed
- [x] **Vector database integration for memory** - Ephemeral knowledge graph & vector store
- [x] **Cloud LLM provider support** - Anthropic Claude & OpenAI GPT integration
- [x] **File safety validation** - Read-before-write enforcement
- [x] **Comprehensive system checks** - 30+ validation mechanisms

### ğŸš§ In Progress
- [ ] Multi-user support with authentication
- [ ] Web-based UI alongside TUI
- [ ] Agent collaboration and handoff
- [ ] Persistent tool call logging

### ğŸ”® Planned
- [ ] Plugin system for third-party extensions
- [ ] Docker containerization improvements
- [ ] Performance profiling and optimization
- [ ] Advanced knowledge graph persistence
- [ ] Real-time agent collaboration protocols

---

## ğŸ› Troubleshooting

### Ollama Connection Issues

**Problem**: "Cannot connect to Ollama"

**Solution**:
```bash
# Check if Ollama is running
ollama list

# Start Ollama service
ollama serve

# Verify endpoint
curl http://localhost:11434/api/tags
```

### Model Not Found

**Problem**: Model doesn't appear in `/models` list

**Solution**:
```bash
# Pull the model
ollama pull llama3.1

# Verify it's available
ollama list
```

### Agent Creation Fails

**Problem**: Agent doesn't save or appears broken

**Solution**:
- Ensure the `./agents` directory exists
- Check file permissions
- Verify YAML frontmatter syntax
- Review agent ID for special characters (use lowercase, hyphens only)

### File Validation Error

**Problem**: "File has not been read yet. Read it first before writing to it"

**Solution**:
```typescript
// Read the file first
await readFile({ path: 'myfile.txt' });

// Then write to it
await writeFile({ path: 'myfile.txt', content: 'updated' });
```

This is a safety feature to prevent accidental overwrites. See [FILE_READ_WRITE_VALIDATION.md](./docs/FILE_READ_WRITE_VALIDATION.md) for details.

### Provider Switching Issues

**Problem**: Cannot switch to Anthropic or OpenAI

**Solution**:
- Ensure API key is configured in environment or via LLM config
- Check provider is enabled: `/providers`
- Verify API key is valid and has sufficient credits
- Check network connectivity for cloud providers

---

## ğŸ“š Documentation

### Core Documentation
- **[SYSTEM_CHECKS.md](./docs/SYSTEM_CHECKS.md)** - Complete catalog of all 30+ validation mechanisms
- **[FILE_READ_WRITE_VALIDATION.md](./docs/FILE_READ_WRITE_VALIDATION.md)** - File safety validation guide

### Knowledge Graph & Memory
- **[Knowledge Graph Tools](./src/lib/tools/knowledge-tools.ts)** - 5 specialized tools for querying the knowledge graph
- **[Systematic Agent Prompts](./src/lib/agents/SystematicAgentPrompts.ts)** - Agent prompts with KG documentation

### Provider Configuration
- **[LLM Configuration](./src/lib/config/LLMConfig.ts)** - Multi-provider management system
- **[Provider Implementations](./src/lib/providers/)** - Anthropic, OpenAI, and Ollama integrations

### Testing
- **[File Validation Tests](./test-file-validation.ts)** - Run with `npx tsx test-file-validation.ts`

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **Ollama**: For providing excellent local LLM infrastructure
- **Ink**: For the React-based terminal UI framework
- **TypeScript**: For making JavaScript development sane
- **Model Context Protocol**: For standardized tool interfaces

---

## ğŸ“§ Contact & Support

- **Issues**: [GitHub Issues](https://github.com/k5tuck/CC_Clone/issues)
- **Discussions**: [GitHub Discussions](https://github.com/k5tuck/CC_Clone/discussions)

---

**Built with â¤ï¸ by the Selek Team**

*Empowering developers to build the future of AI agents, locally.*
